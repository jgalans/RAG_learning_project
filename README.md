# ProyectoRAG - Sistema de RecomendaciÃ³n de Productos con IA

Un sistema inteligente de bÃºsqueda y recomendaciÃ³n de productos basado en **RAG (Retrieval-Augmented Generation)** que utiliza embeddings vectoriales y modelos de lenguaje para entender consultas naturales.

## ğŸ¯ Â¿QuÃ© es este proyecto?

Este proyecto implementa un **sistema RAG** que:

1. **Convierte productos a vectores** usando embeddings de `sentence-transformers`
2. **Busca productos similares** a la consulta del usuario usando bÃºsqueda vectorial con ChromaDB
3. **Genera recomendaciones personalizadas** usando un LLM (Llama2 con Ollama)

### Flujo completo:

```
Pregunta del usuario
    â†“
Embeddings (texto â†’ nÃºmeros)
    â†“
BÃºsqueda vectorial (encontrar productos similares)
    â†“
LLM (generar respuesta natural)
    â†“
RecomendaciÃ³n personalizada
```

## ğŸš€ Requisitos

- Python 3.9+
- Ollama (para el LLM)
- Las librerÃ­as en `requirements.txt`

## ğŸ“¦ InstalaciÃ³n

### 1. Clonar el repositorio

```bash
git clone https://github.com/TU_USUARIO/ProyectoRAG.git
cd ProyectoRAG
```

### 2. Crear entorno virtual

```bash
python -m venv .venv
source .venv/bin/activate  # En macOS/Linux
# o
.venv\Scripts\activate  # En Windows
```

### 3. Instalar librerÃ­as

```bash
pip install -r requirements.txt
```

### 4. Instalar Ollama

Descarga Ollama desde: https://ollama.ai

Luego, inicia el servidor:

```bash
ollama serve
```

En otra terminal, descarga el modelo Llama2:

```bash
ollama pull llama2
```

## ğŸ® Uso

### Ejecutar el script

```bash
python ia_tienda.py
```

### Modificar la pregunta

Edita la lÃ­nea en `ia_tienda.py`:

```python
pregunta = "ropa para hacer deporte y correr cuando hace sol"
```

Cambia el texto a tu consulta deseada.

## ğŸ“‚ Estructura del proyecto

```
ProyectoRAG/
â”œâ”€â”€ ia_tienda.py          # Script principal con RAG
â”œâ”€â”€ setup_db.py           # Script para crear la BD de productos
â”œâ”€â”€ requirements.txt      # Dependencias
â”œâ”€â”€ ecommerce.db          # Base de datos (SQLite)
â”œâ”€â”€ data/                 # Datos del proyecto
â””â”€â”€ README.md             # Este archivo
```

## ğŸ”§ Componentes principales

### `ia_tienda.py`

- **HuggingFaceEmbeddings**: Convierte texto a vectores usando `sentence-transformers`
- **ChromaDB**: Base de datos vectorial en memoria para bÃºsqueda rÃ¡pida
- **Ollama (Llama2)**: LLM que genera respuestas naturales
- **LLMChain**: Cadena que une prompt + LLM

### `setup_db.py`

Script para crear y poblar la base de datos de productos.

## ğŸ¤” Â¿QuÃ© es `k=2`?

En `vectorstore.similarity_search(pregunta, k=2)`:

- **k=2** â†’ devuelve los 2 productos mÃ¡s similares a la pregunta
- **k=1** â†’ devuelve solo 1 resultado
- **k=5** â†’ devuelve los 5 mÃ¡s similares

Los resultados se ordenan por **relevancia** (de mayor a menor similitud).

## ğŸ“Š Ejemplo de uso

**Entrada:**
```
Pregunta: "ropa para hacer deporte y correr cuando hace sol"
```

**Proceso:**
1. Se convierte la pregunta a vector
2. Se buscan los 2 productos mÃ¡s similares
3. El LLM genera una recomendaciÃ³n personalizada

**Salida:**
```
=== RESPUESTA DEL LLM ===
Para correr cuando hace sol, te recomiendo la Gorra Running porque 
tiene material transpirable que mantiene tu cabeza fresca. La Camiseta 
Eco es perfecta porque el algodÃ³n orgÃ¡nico es cÃ³modo y respirable...
```

## ğŸ› ï¸ TecnologÃ­as utilizadas

- **Python 3.9+**
- **LangChain** - Framework para IA
- **sentence-transformers** - Embeddings de texto
- **ChromaDB** - Base de datos vectorial
- **Ollama + Llama2** - LLM local gratuito
- **pandas** - ManipulaciÃ³n de datos

## ğŸ“ Licencia

Este proyecto es de cÃ³digo abierto.

## ğŸ¤ Contribuciones

Si quieres mejorar el proyecto, Â¡adelante! Puedes:

1. Hacer un fork del repositorio
2. Crear una rama con tu mejora
3. Hacer un commit con tus cambios
4. Hacer push y crear una Pull Request

## â“ Preguntas frecuentes

**Â¿Por quÃ© tarda en la primera ejecuciÃ³n?**

Porque descarga el modelo de embeddings (~100MB) la primera vez.

**Â¿Puedo usar otro LLM?**

SÃ­, puedes cambiar `Ollama(model="llama2")` por:
- `OpenAI()` (requiere API key)
- `HuggingFaceLLM()` (otros modelos open-source)

**Â¿Funciona sin internet?**

SÃ­, una vez que tengas Ollama y los modelos descargados.

