ğŸ¤– ProyectoRAG: Recomendador Inteligente para E-commerce
Este proyecto implementa un sistema de GeneraciÃ³n Aumentada por RecuperaciÃ³n (RAG) que permite consultar un catÃ¡logo de productos mediante lenguaje natural. A diferencia de una bÃºsqueda tradicional por palabras clave, este sistema entiende la intenciÃ³n del usuario y genera una respuesta amable y personalizada.

ğŸ¯ Capacidades del Sistema
Memoria SemÃ¡ntica: Convierte las descripciones de productos y precios en vectores numÃ©ricos.

BÃºsqueda Contextual: Encuentra productos no solo por su nombre, sino por su utilidad (ej: "algo para el calor").

Razonamiento con LLM: Utiliza Llama2 para explicar por quÃ© esos productos especÃ­ficos encajan con la duda del usuario.

ğŸ› ï¸ TecnologÃ­as Utilizadas
LangChain (v0.3+): Orquestador del pipeline de IA (usando sintaxis LCEL).

Ollama: Servidor local para correr modelos de lenguaje (LLM).

ChromaDB: Base de datos vectorial persistente.

HuggingFace: Modelo de embeddings all-MiniLM-L6-v2.

SQLite & Pandas: GestiÃ³n de la base de datos relacional original.

ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n
1. Clonar y Preparar el Entorno
Bash

git clone https://github.com/TU_USUARIO/ProyectoRAG.git
cd ProyectoRAG

# Crear entorno virtual
python3 -m venv .venv
source .venv/bin/activate  # En Windows: .venv\Scripts\activate

# Instalar dependencias actualizadas
pip install -r requirements.txt
2. Configurar el "Cerebro" (Ollama)
AsegÃºrate de tener Ollama instalado y ejecutÃ¡ndose:

Bash

ollama pull llama2
3. Preparar los Datos
Si es la primera vez que lo usas, crea la base de datos de productos:

Bash

python setup_db.py
ğŸ® Funcionamiento
Ejecuta el recomendador:

Bash

python ia_tienda.py
Â¿CÃ³mo funciona internamente?
El sistema sigue la nueva sintaxis de LangChain (LCEL):

Retrieval: Busca los k productos mÃ¡s cercanos en la base de datos vectorial chroma_db/.

Augment: Inyecta esos productos y el precio en un PromptTemplate.

Generate: EnvÃ­a todo a Llama2 mediante chain.invoke() para obtener la respuesta final.

ğŸ“‚ Estructura del Proyecto
Plaintext

ProyectoRAG/
â”œâ”€â”€ ia_tienda.py         # LÃ³gica RAG con LCEL e Invoke
â”œâ”€â”€ setup_db.py          # Script de creaciÃ³n de DB SQLite
â”œâ”€â”€ ecommerce.db         # Base de datos relacional de productos
â”œâ”€â”€ chroma_db/           # Carpeta de persistencia vectorial (auto-generada)
â”œâ”€â”€ requirements.txt     # Dependencias (versiones bloqueadas)
â””â”€â”€ .gitignore           # Archivo para ignorar .venv y bases de datos
ğŸ“ Notas de VersiÃ³n (v2.0)
MigraciÃ³n de LibrerÃ­as: Se ha actualizado de langchain_community a paquetes especÃ­ficos como langchain-huggingface y langchain-ollama.

Cambio a Invoke: Se eliminÃ³ el mÃ©todo depreciado .run() en favor de .invoke().

Persistencia: La base de datos vectorial ahora se guarda localmente para evitar regenerar embeddings en cada ejecuciÃ³n.

ğŸ’¡ Â¿QuÃ© sigue?
Si te gusta este proyecto, puedes probar a:

Aumentar el valor de k en similarity_search para dar mÃ¡s opciones al LLM.

Cambiar el modelo en Ollama (ej: mistral o llama3) para comparar respuestas.
